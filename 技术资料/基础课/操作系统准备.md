# 操作系统基本概念

# 基本特征

#### 并发

并发是指宏观上在一段时间内能同时运行多个程序，而并行则指同一时刻能运行多个指令。

并行需要硬件支持，如多流水线、多核处理器或者分布式计算系统。

操作系统通过引入进程和线程，使得程序能够并发运行。

#### 共享

共享是指系统中的资源可以被多个并发进程共同使用。

有两种共享方式：互斥共享和同时共享。

互斥共享的资源称为临界资源，例如打印机等，在同一时间只允许一个进程访问，需要用同步机制来实现对临界资源的访问。

#### 虚拟

虚拟技术把一个物理实体转换为多个逻辑实体。

主要有两种虚拟技术：时分复用技术和空分复用技术。

多个进程能在同一个处理器上并发执行使用了时分复用技术，让每个进程轮流占有处理器，每次只执行一小个时间片并快速切换。

虚拟内存使用了空分复用技术，它将物理内存抽象为地址空间，每个进程都有各自的地址空间。地址空间的页被映射到物理内存，地址空间的页并不需要全部在物理内存中，当使用到一个没有在物理内存的页时，执行页面置换算法，将该页置换到内存中。

#### 异步

异步指进程不是一次性执行完毕，而是走走停停，以不可知的速度向前推进。





# 进程管理

### 进程和线程的由来

![](/Users/Haoyu/Documents/typora/java/assets/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B%E7%9A%84%E7%94%B1%E6%9D%A5.png)

### 进程和线程的区别

​	**进程是资源分配的最小单位，线程是cpu调度的最小单位。**

​	一个进程可以有多个线程。每个线程必属于一个进程。

### 用户态与内核态

如果一个进程在用户态需要使用内核态的功能，就进行系统调用从而陷入内核，由操作系统代为完成。

##### Unix/Linux的体系架构

![](../assets/linux:unix%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84.png)

​	如上图所示，从宏观上来看，Linux操作系统的体系架构分为用户态和内核态（或者用户空间和内核）。**内核从本质上看是一种软件——控制计算机的硬件资源，并提供上层应用程序运行的环境**。

**用户态即上层应用程序的活动空间，应用程序的执行必须依托于内核提供的资源，包括CPU资源、存储资源、I/O资源等**。为了使上层应用能够访问到这些资源，内核必须为上层应用提供访问的接口：即系统调用。

> 内核态，必须为上层应用提供访问接口，访问计算机的CPU资源，存储资源和IO资源，这也是Java虚拟机中为什么有本地方法栈道原因，因为根据隔离思想，用户无法接触到操作系统内核

​	**系统调用是操作系统的最小功能单位**，这些系统调用根据不同的应用场景可以进行扩展和裁剪，现在各种版本的Unix实现都提供了不同数量的系统调用，如Linux的不同版本提供了240-260个系统调用，FreeBSD大约提供了320个（reference：UNIX环境高级编程）。

​	**我们可以把系统调用看成是一种不能再化简的操作（类似于原子操作，但是不同概念），有人把它比作一个汉字的一个“笔画”，而一个“汉字”就代表一个上层应用**，我觉得这个比喻非常贴切。因此，有时候如果要实现一个完整的汉字（给某个变量分配内存空间），就必须调用很多的系统调用。如果从实现者（程序员）的角度来看，这势必会加重程序员的负担，**良好的程序设计方法是：重视上层的业务逻辑操作，而尽可能避免底层复杂的实现细节**。

​	**库函数正是为了将程序员从复杂的细节中解脱出来而提出的一种有效方法。它实现对系统调用的封装，将简单的业务逻辑接口呈现给用户，方便用户调用，从这个角度上看，库函数就像是组成汉字的“偏旁”**。这样的一种组成方式极大增强了程序设计的灵活性，对于简单的操作，我们可以直接调用系统调用来访问资源，如“人”，对于复杂操作，我们借助于库函数来实现，如“仁”。显然，这样的库函数依据不同的标准也可以有不同的实现版本，如ISO C 标准库，POSIX标准库等。

​	**Shell是一个特殊的应用程序，俗称命令行**，本质上是一个命令解释器，它下通系统调用，上通各种应用，通常充当着一种“胶水”的角色，来连接各个小功能程序，让不同程序能够以一个清晰的接口协同工作，从而增强各个程序的功能。

​	同时，Shell是可编程的，它可以执行符合Shell语法的文本，这样的文本称为Shell脚本，通常短短的几行Shell脚本就可以实现一个非常大的功能，原因就是这些Shell语句通常都对系统调用做了一层封装。为了方便用户和系统交互，一般，一个Shell对应一个终端，终端是一个硬件设备，呈现给用户的是一个图形化窗口。我们可以通过这个窗口输入或者输出文本。这个文本直接传递给shell进行分析解释，然后执行。

​	**总结一下，用户态的应用程序可以通过三种方式来访问内核态的资源：**

- 系统调用
- 库函数
- Shell脚本

​	下图是对上图的一个细分结构，从这个图上可以更进一步对内核所做的事有一个“全景式”的印象。主要表现为：向下控制硬件资源，向内管理操作系统资源：包括进程的调度和管理、内存的管理、文件系统的管理、设备驱动程序的管理以及网络资源的管理，向上则向应用程序提供系统调用的接口。从整体上来看，整个操作系统分为两层：用户态和内核态，这种分层的架构极大地提高了资源管理的可扩展性和灵活性，而且方便用户对资源的调用和集中式的管理，带来一定的安全性。

![](/Users/Haoyu/Documents/typora/%E5%9F%BA%E7%A1%80%E8%AF%BE/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9Fassets/linux:unix%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E7%BB%86%E5%88%86.png)

##### **用户态和内核态的切换**

​	因为操作系统的资源是有限的，如果访问资源的操作过多，必然会消耗过多的资源，而且如果不对这些操作加以区分，很可能造成资源访问的冲突。所以，为了减少有限资源的访问和使用冲突，Unix/Linux的设计哲学之一就是：对不同的操作赋予不同的执行等级，就是所谓特权的概念。简单说就是有多大能力做多大的事，与系统相关的一些特别关键的操作必须由最高特权的程序来完成。

​	Intel的X86架构的CPU提供了0到3四个特权级，数字越小，特权越高，Linux操作系统中主要采用了0和3两个特权级，分别对应的就是内核态和用户态。

​	运行于用户态的进程可以执行的操作和访问的资源都会受到极大的限制，而运行在内核态的进程则可以执行任何操作并且在资源的使用上没有限制。

**很多程序开始时运行于用户态，但在执行的过程中，一些操作需要在内核权限下才能执行，这就涉及到一个从用户态切换到内核态的过程**。比如C函数库中的内存分配函数malloc()，它具体是使用sbrk()系统调用来分配内存，当malloc调用sbrk()的时候就涉及一次从用户态到内核态的切换，类似的函数还有printf()，调用的是wirte()系统调用来输出字符串，等等。

![](/Users/Haoyu/Documents/typora/%E5%9F%BA%E7%A1%80%E8%AF%BE/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9Fassets/%E7%94%A8%E6%88%B7%E6%80%81%E5%88%B0%E5%86%85%E6%A0%B8%E6%80%81%E7%9A%84%E5%88%87%E6%8D%A2.png)

​	到底在什么情况下会发生从用户态到内核态的切换，一般存在以下三种情况：

- 当然就是系统调用：原因如上的分析。

- 异常事件： 当CPU正在执行运行在用户态的程序时，突然发生某些预先不可知的异常事件，这个时候就会触发从当前用户态执行的进程转向内核态执行相关的异常事件，典型的如缺页异常。

  //用户态转向内核态执行，由操作系统代劳

- 外围设备的中断：当外围设备完成用户的请求操作后，会像CPU发出中断信号，此时，CPU就会暂停执行下一条即将要执行的指令，转而去执行中断信号对应的处理程序，如果先前执行的指令是在用户态下，则自然就发生从用户态到内核态的转换。

　　注意：系统调用的本质其实也是中断，相对于外围设备的硬中断，这种中断称为软中断，这是操作系统为用户特别开放的一种中断，如Linux int 80h中断。所以，从触发方式和效果上来看，这三种切换方式是完全一样的，都相当于是执行了一个中断响应的过程。但是从触发的对象来看，系统调用是进程主动请求切换的，而异常和硬中断则是被动的。

##### 补充：中断的概念，硬中断，软中断

**BLOCKED**

A thread that is blocked waiting for a monitor lock is in this state.

**WAITING**

A thread that is waiting indefinitely for another thread to perform a 
particular action is in this state.

**TIMED_WAITING**

A thread that is waiting for another thread to perform an action for 
up to a specified waiting time is in this state.

时间确定 
通过sleep或wait timeout方法进入的限期等待的状态)

NEW和TERMINATED对于中断操作几乎是屏蔽的，RUNNABLE和BLOCKED类似，对于中断操作只是设置中断标志位并没有强制终止线程，对于线程的终止权利依然在程序手中。WAITING/TIMED_WAITING状态下的线程对于中断操作是敏感的，他们会抛出异常并清空中断标志位。

不同线程状态对中断的反应



中断是正在运行的主程序被打断，进而去运行中断程序，之后再折回来，有点类似函数调用的感觉，比如主程序中断去做io，而io又有io等待，真正浪费CPU资源的，不是对中断程序的执行，而是IO等待时间，IO等待时间，CPU是空闲的，因此如果

一、对于wait中等待notify/notifyAll唤醒的线程，其实这个线程已经"暂停"执行，因为它正在某一对象的休息室中，这时如果它的中断状态被改变，那么它就会抛出异常。这个InterruptedException异常不是线程抛出的，而是wait方法，也就是对象的wait方法内部
会不断检查在此对象上休息的线程的状态，如果发现哪个线程的状态被置为已中断，则会抛出InterruptedException，意思就是这个线程不能再等待了，其意义就等同于唤醒它了。

　　这里唯一的区别是，被notify/All唤醒的线程会继续执行wait下面的语句，而在wait中被中断的线程则将控制权交给了catch语句.一些正常的逻辑要被放到catch中来运行。
　　但有时这是唯一手段，比如一个线程a在某一对象b的wait中等待唤醒，其它线程必须获取到对象b的监视锁才能调用b.notify()[All]，否则你就无法唤醒线程a，但在任何线程中可以无条件地调用a.interrupt();来达到这个目的.只是唤醒后的逻辑你要放在catch中，当然同notify/All一样，继续执行a线程的条件还是要等拿到b对象的监视锁。

　　二、对于sleep中的线程，如果你调用了Thread。sleep(一年);现在你后悔了，想让它早些醒过来，调用interrupt()方法就是唯一手段，只有改变它的中断状态，让它从sleep中将控制权转到处理异常的catch语句中，然后再由catch中的处理转换到正常的逻辑。同样，地于join中的线程你也可以这样处理。

##### 补充：中断分类

1. 外中断

   由 CPU 执行指令以外的事件引起，如 I/O 完成中断，表示设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求。此外还有时钟中断、控制台中断等。

2. 异常

3. 系统调用，用户进入内核态

# 进程与线程的区别 ✅

### 进程与线程的区别 ⚠️

进程与线程的层次关系

##### 进程

一个进程可以有多个线程，多个线程可以并发，可以共享进程数据，拥有自己的栈空间和执行序列

首先进程是程序的一次执行，包含代码和数据，是任务独立执行的最小单元

是资源分配的基本单位，进程与线程是不同的系统资源管理方式。进程拥有独立的地址空间，而线程没有。一个进程崩溃后，在保护模式下，不会对其他进程造成影响；

关于子进程和父进程,子进程可以是父进程的复制品，可以获得父进程的数据空间、堆、栈的复制品，linux的fork



##### 线程

线程是进程的一个执行单元

是调度和执行的基本单位，是比进程更小的独立运行单位

而线程只是进程的一个执行路径，没有自己独立的地址空间，一旦一个线程崩溃，整个进程就会崩溃。所以，多进程的程序比多线程程序更加健壮

**线程调度开销更小** 

线程不占用系统资源，调度线程比调度进程开销更小，在线程间切换比在进程间切换效率高。

**线程可以共享进程的资源和变量**

对于一些要求同时进行而又共享某些变量的并发操作来说，只能用多线程，不能用多进程。
同时进行而又要共享变量，有共享区，共享一些值，所以说只能用多线程，不能用多进程。

1. 拥有资源

进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。

2. 调度

线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。

3. 系统开销

由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。

4. 通信方面

线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助 IPC。



### 线程同步的方法

Java里并发的实现机制都是同步互斥访问，但是线程同步的方法其实有很多

1. 互斥(信号)量，每个时刻只有一个线程可以访问公共资源。只有拥有互斥对象的线程才能访问公共资源，互斥对象只有一个，一个时刻只能有一个线程持有，所以保证了公共资源不会被多个线程同时访问。

2. 信号量，允许多个线程同时访问公共资源。当时控制了访问资源的线程的最大个数。

3. 事件 in windows（条件变量 in linux）。通过通知的方式保持多线程的同步，还可以方便的实现多线程优先级的比较

4. 临界区。任意时刻只能有一个线程进入临界区，访问临界资源。

   临界区的实现，还是互斥信号量，才可以保证同一时间只有一个线程进入临界区



### 进程同步的方法也很多

原子操作（互斥，要么都改要么都不改）
信号量
管程

##### 临界区

// entry section
// critical section;
// exit section

有点生产者消费者，进入之后就枷锁

##### 同步与互斥

同步：多个进程按一定顺序执行；

互斥：多个进程在同一时刻只有一个进程能进入临界区。

##### 信号量

##### 管程

使用信号量机制实现的生产者消费者问题需要客户端代码做很多控制，而管程把控制的代码独立出来，不仅不容易出错，也使得客户端代码调用更容易。

有一个重要特性：在一个时刻只能有一个进程使用管程。进程在无法继续执行的时候不能一直占用管程，否则其它进程永远不能使用管程。

管程引入了 **条件变量** 以及相关的操作：**wait()** 和 **signal()** 来实现同步操作。对条件变量执行 wait() 操作会导致调用进程阻塞，把管程让出来给另一个进程持有。signal() 操作用于唤醒被阻塞的进程。

### 进程有几种状态

新建进程->加载->就绪，调度，运行 执行完了：释放 等待IO：阻塞 

时间片用完:就绪 阻塞后 可以被唤醒notify() 到就绪状态

##### 三态图

![](/Users/Haoyu/Documents/typora/%E5%9F%BA%E7%A1%80%E8%AF%BE/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9Fassets/%E7%BA%BF%E7%A8%8B%E4%B8%89%E6%80%81%E5%9B%BE.png)

##### 五态图

![](/Users/Haoyu/Documents/typora/%E5%9F%BA%E7%A1%80%E8%AF%BE/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9Fassets/%E7%BA%BF%E7%A8%8B%E4%BA%94%E6%80%81%E5%9B%BE.png)

##### 七态图

![](/Users/Haoyu/Documents/typora/%E5%9F%BA%E7%A1%80%E8%AF%BE/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9Fassets/%E7%BA%BF%E7%A8%8B%E4%B8%83%E6%80%81%E5%9B%BE.png)

### 

#### 进程创建过程

给新进程分配一个唯一的标识符
给进程分配内存空间
初始化进程控制块PCB：进程存在的唯一标识
将PCB放入就绪队列中，等待分配CPU资源



代码 数据 常量，堆 栈 

### 进程之间的通信方式

进程同步与进程通信很容易混淆，它们的区别在于：

- 进程同步：控制多个进程按一定顺序执行；
- 进程通信：进程间传输信息。

##### 通信类型

![](../assets/%E8%BF%9B%E7%A8%8B%E9%80%9A%E4%BF%A1%E7%B1%BB%E5%9E%8B.png)

##### 信号量通信

​	低级通信方式，效率低，管理困难。

##### FIFO 命名管道

去除了管道只能在父子进程之间使用的限制

FIFO 常用于客户-服务器应用程序中，FIFO 用作汇聚点，在客户进程和服务器进程之间传递数据。

##### 共享存储区

​	相互通信的进程通过共享数据结构或共享存储区进行通信。用信号量来控制，因此这是最快的一种调度方式

- 共享数据结构：诸进程通过公用某些数据结构交换信息。如生产者-消费者问题。（低效，只适于传递少量数据）
- 共享存储器：◦为了传送大量数据，在存储器中划出一块共享存储区，诸进程可通过对共享存储区进行读或写来实现通信。包括建立共享存储区、附接及断接。

##### 消息传递系统通信(消息队列)

​	在消息传递系统中，进程间的数据交换以消息为单位，程序员直接利用系统提供的一组通信命令（原语）来实现通信。消息传递系统因其实现方式不同可分为直接通信方式和间接通信方式。

- 直接通信方式（消息缓冲通信）：发送进程将消息发送到接收进程，并将其挂在接收进程的消息队列上；接收进程从消息队列上取消息。
- 间接通信方式（信箱通信）：发送进程将消息发送到信箱，接收进程从信箱中取消息。

​	这个就有点像kafka那样的了



**信箱通信**

​	消息在信箱中可以安全地保存，只允许核准的目标用户随时读取。因此，利用信箱通信方式，既可实现实时通信，又可实现非实时通信。

​	信箱可由操作系统创建，也可由用户进程创建，创建者是信箱的拥有者。据此，可把信箱分为以下三类：

- 私用邮箱

- 公用邮箱

- 共享邮箱

  在利用信箱通信时，在发送进程和接收进程之间，存在以下四种关系：

- 一对一关系

- 多对一关系

- 一对多关系

- 多对多关系

##### 管道系统通信(Pipe) 

pipe 只支持半双工通信，也就是说双方交替发信息

只能在父子进程中使用

​	通过连接读进程和写进程的共享文件来实现读写进程之间通信。

- 管道(pipeline)是连接读写进程的一个特殊文件，允许进程按先进先出方式传送数据，也能使进程同步执行操作。
- 发送进程以字符流形式把大量数据送入管道，接收进程从管道中接收数据，所以叫管道通信。
- 管道的实质是一个共享文件，基本上可借助于文件系统的机制实现，包括（管道）文件的创建、打开、关闭和读写。
- 管道机制需要提供一下几点的协调能力
  - 互斥，即当一个进程正在对pipe执行读/写操作时，其它进程必须等待

  - 同步，当一个进程将一定数量的数据写入，然后就去睡眠等待，直到读进程将数据取走，再去唤醒。读进程与之类似

    //半双工的方式，一个进程写入数据，等待，等待其他进程取走

  - 确定对方是否存在

##### 补充：什么是父子进程？

​	调用fork以后创建的复制进程又叫子进程，并且父进程有指向字进程的指针



### 进程同步问题

##### 消费者生产者问题

- 问题描述：

  一组生产者进程向一组消费者进程提供产品，他们共享一个有界缓冲池。缓冲池中每个缓冲区可以存放一个产品，生产者进程不断生产产品并将产品放入缓冲池中，消费者进程不断从缓冲池内取出产品并消费。此外，指定时刻内只有一个线程能进入缓冲池（用的是临界区的进程同步原理），当缓冲池满时生产者需要等待，当缓冲池空时消费者需要等待。

  ![](../assets/%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E8%B4%B9%E8%80%85%E9%97%AE%E9%A2%98%E7%A4%BA%E6%84%8F%E5%9B%BE.png)

- 问题解决：

  1. 使用记录型信号量解决问题

     设置两个同步信号量empty、full，分别表示空缓冲缓冲区的数量和满缓冲区的数量，empty 初值为n，full初值为0。有界缓冲池是一个临界资源，还需要设置一个互斥信号量mutex，其初值为1。

     ![](../assets/%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E8%B4%B9%E8%80%85%E8%AE%B0%E5%BD%95%E5%9E%8B%E4%BF%A1%E5%8F%B7%E9%87%8F%E8%A7%A3%E5%86%B3.png)

     注：无论在生产者进程还是在消费者进程中，wait操作的次序都不能颠倒，否则将可能造成死锁

     同一时间，对缓冲区只有一个生产者/消费者线程可以进行读写

  2. 使用AND型信号量解决问题

     ![](../assets/消费者生产者and型信号量解决问题.png)



##### 哲学家进餐问题

- 问题描述

  有几个哲学家，他们的生活方式是交替地进行思考和进餐，哲学家们公用一张圆桌，分别坐在周围的五张椅子上，在圆桌上有五个碗和五支筷子。平时哲学家进行思考，饥饿时试图获取其左右最靠近他的筷子，只有在他拿到两支筷子时才能进餐。进餐完毕，放下筷子继续思考。

  ![](../assets/哲学家进餐问题.png)

- 问题解决

  用五支筷子的信号量构成信号量数组：`var chopstick: arr[0, …, 4]'`，所有信号量的初始值为1。

  1. 用记录型信号量解决哲学家进餐问题：

     ![](../assets/%E5%93%B2%E5%AD%A6%E5%AE%B6%E8%BF%9B%E9%A4%90%E9%97%AE%E9%A2%98%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95%E5%9E%8B%E4%BF%A1%E5%8F%B7%E9%87%8F%E8%A7%A3%E5%86%B3.png)

     上述算法有可能引起死锁：当五个哲学家同时感觉饥饿，且同时拿起自己左边的筷子…

     对于这样的死锁问题有如下办法解决：

     - 至多允许四个哲学家同时进餐。
     - 仅当左、右两支筷子均可用时，才允许拿起筷子进餐。
     - 奇数号哲学家先拿左边筷子再拿右边筷子，偶数号哲学家相反。

  2. 用And型信号量解决问题：

     每个哲学家要先获得两个临界资源(筷子)后方能进餐，用AND信号量机制可获得最简洁的解法。算法流程如下：

     ![](../assets/哲学家进餐问题AND型信号量解决.png)





##### 读者写者问题

- 问题描述

  一个数据对象（如文件或记录）可以被多个并发进程所共享，其中有些进程只要求读数据对象的内容（称为读者），而另一些进程则要求修改或写数据对象的内容（称为写者），允许多个读者同时读此数据对象，但是一个写者不能与其他进程（不管是写者还是读者）同时访问此数据对象。

- 问题解决

  为解决读者写者问题，应设置两个信号量和一个共享变量：

  - 共享整型变量readcount，用于记录当前正在读数据的读者数目，初值为0。
  - 信号量rmutex，用于使读者互斥地访问共享变量readcount，其初值为1；
  - 信号量wmutex，用于实现写者与读者的互斥以及写者与写者的互斥，其初值为1；

  ![](../assets/%E8%AF%BB%E8%80%85%E5%86%99%E8%80%85%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95%E5%9E%8B%E4%BF%A1%E5%8F%B7%E9%87%8F%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88.png)

  ![](../assets/%E8%AF%BB%E8%80%85%E5%86%99%E8%80%85%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95%E5%9E%8B%E4%BF%A1%E5%8F%B7%E9%87%8F%E8%A7%A3%E5%86%B32.png)

  注：如果有一个写者在临界区内，且n个读者处于等待，那么一个读者在wmutex上排队，而n-1个读者在rmutex上排队。



# 进程调度 ✅

### 批处理系统

批处理系统没有太多的用户操作，在该系统中，调度算法目标是保证吞吐量和周转时间（从提交到终止的时间）。

FCFS 先来先服务

SJF 短作业优先调度 按估计运行时间最短来调度，但是长进程可能会饥饿而死

SRTN 最短剩余时间调度  按估计剩余时间最短来调度 **怎么估计呢？经验？我记得书上有讲的**

### 交互式系统

RR 时间片轮转调度算法

优先级调度 为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。

多级反馈队列调度 RR和优先级调度的结合







1. 简介

   进程调度的主要任务是协调进程对CPU的竞争，即按照某种策略（**调度算法**）从就绪队列中选取一个进程，将处理机分配给它。进程调度是操作系统最为核心的部分，进程调度策略的优劣直接影响到整个系统的性能。进程调度的运行频率很高，一般几十毫秒要运行一次。 

2. 进程调度的功能

   - 保存处理机的现场信息
   - 按调度算法选择进程运行
   - 由分配程序实施处理机的分配及回收

3. 进程调度的两种方式

   - 抢占式

     ​	又称剥夺方式、可剥夺方式。这种调度方式是指允许调度程序根据某种原则去停止正在执行的进程，将已分配给该进程的处理机重新分配给其他进程。

     ​	抢占原则有：优先权、短作业优先、时间片等。

     ​	特点：系统响应性高，但增加系统开销 。

   - 非抢占式

     ​	又称非剥夺方式、不可剥夺方式、不可抢占方式。这种调度方式是指一旦将处理机分配给某进程后，便让该进程一直执行，直到该进程完成或发生某事件而进入阻塞状态，才把处理机分配给其他进程。

     ​	特点：简单，系统开销小，但无法处理紧急任务。

4. 进程调度发生的时机

   - 抢占式
     - 当一个进程终止
     - 当一个进程由运行态转到等待态
     - 当一个进程由运行态转到就绪态（时间片到）
     - 当一个进程由等待态转到就绪态（高优先级进程就绪、短作业就绪）
   - 非抢占式
     - 当一个进程终止
     - 当一个进程由运行态转到等待态

### 调度算法

##### 简介

​	本章的算法有些适合作业调度，有些适合进程调度，有些适用于两者。对于作业调度，调度算法决定从后备作业队列中选择哪一个（一批）作业，调入内存执行。对于进程调度，调度算法决定从就绪队列选择哪一个进程，给它分配处理机。

##### 周转时间相关概念

- 周转时间

  作业的周转时间是指从作业提交到作业完成之间的时间间隔。即：`周转时间＝完成时刻－提交时刻`。实际上，它是作业在系统里的等待时间与实际运行时间之和。

- 平均周转时间

  平均周转时间是指多个作业的周转时间的平均值。即*n*个作业的平均周转时间：

$$
T = \frac{1}{n}*T_i，T_i为作业i的周转时间
$$

- 带权周转时间

  带权周转时间是指作业周转时间与作业实际运行时间的比。

- 平均带权周转时间

  平均带权周转时间是指多个作业的带权周转时间的平均值。即*n*个作业的平均带权周转时间
  $$
  W = \frac{1}{n}*\frac{T_i}{T_{S_i}}，T_i为作业i的周转时间，T_{S_i}为作业i的实际运行时间
  $$

##### 先来先服务调度算法

1. 简介

   **先来先服务调度算法**（First-Come First-Served，FCFS），FCFS算法总是选择最先到达的作业或进程。}在进程调度中，从就绪队列中选择一个最先进入该队列的进程，为之分配处理机，使之投入运行。该进程一直运行到完成或因等待某一事件而阻塞时才释放处理机。非抢占式。

2. 特点

   - 算法简单，易于实现，
   - 有利于长作业，不利于短作业
   - 有利于CPU繁忙型作业，不利于I/O繁忙型作业 ，可能导致I/O设备和CPU利用率低
   - 未考虑作业的紧迫程度

3. 实际测试

   测试用例如下：

   ![](../assets/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%E6%B5%8B%E8%AF%95%E7%94%A8%E4%BE%8B.png)

   先到先服务的性能指标如下：

   ![](../assets/%E5%85%88%E5%88%B0%E5%85%88%E6%9C%8D%E5%8A%A1%E6%B5%8B%E8%AF%95%E7%94%A8%E4%BE%8B.png)

##### 短作业优先调度算法

1. 简介

   短作业优先调度算法(Shortest Job/Process First，SJF或SPF)，该算法总是选择估计运行时间最短的作业或进程。若无特殊说明，短作业优先调度算法为非抢占式调度算法。但其也可以为抢占式调度算法(最短剩余时间调度算法)。

2. 特点

   - 算法调度性能较好，数据详情见测试部分，可以证明：**多个作业同时到达时，短作业优先调度算法的平均周转时间最小。**
   - 缺点是对长作业不利；未考虑作业的紧迫程度；需要估计运行时间。

3. 实际测试

   测试用例与先来先服务中的测试用例相同，测试结果如下：

   ![](../assets/%E7%9F%AD%E4%BD%9C%E4%B8%9A%E4%BC%98%E5%85%88%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%E6%B5%8B%E8%AF%95%E7%94%A8%E4%BE%8B.png)

##### 最短剩余时间优先调度算法

1. 简介

   最短剩余时间优先调度算法(Shortest Remaining Time Next，SRT)。**抢占式的最短进程优先调度算法也称为最短剩余时间优先调度算法**，即当一个新进程进入就绪队列时，若其需要的运行时间比当前运行进程的剩余时间短，则它将抢占CPU。

2. 实际测试

   ![](../assets/%E6%9C%80%E7%9F%AD%E5%89%A9%E4%BD%99%E6%97%B6%E9%97%B4%E4%BC%98%E5%85%88%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95.png)

##### 优先权调度算法

1. 简介

   优先权调度算法(Priority Scheduling or High Priority First，HPF )。选择优先权最高的作业或进程。其具体可以细分为**非抢占式优先权算法**和**抢占式优先权算法**：

   - 非抢占式优先权算法：

     系统一旦将处理机分配给就绪队列中优先权最高的进程后，该进程便一直运行下去，直到完成或因发生某事件使该进程放弃处理机时，系统才将处理机分配给另一个更高优先权的进程。

   - 抢占式优先权算法：

     将处理机分配给优先权最高的进程，使之运行。在进程运行过程中，一旦出现了另一个优先权更高的进程时，进程调度程序就停止原运行进程，而将处理机分配给新出现的高优先权进程。

2. 优先权的类型

   优先权分为两种：静态优先权和动态优先权。

   - 静态优先权

     静态优先权是在创建进程时确定的，确定之后在整个进程运行期间不再改变。

     确定静态优先权的依据有：

     - 进程类型：系统，用户
     - 进程对资源的需求：执行时间，资源数量
     - 用户要求：紧迫程度
     - 到达时间：先到则优先权高

     特点：简单易行，系统开销小，但不精确，可能出现低优先权进程长期不被调度的情况。

   - 动态优先权

     动态优先权是指在创建进程时，根据进程的特点及相关情况确定一个优先权，在进程运行过程中再根据情况的变化调整优先权。

     调整动态优先权的原则有：

     - 占用CPU时间越长，优先权越低
     - 等待时间越长，优先权越高

##### 最高响应比优先调度算法

1. 简介

   最高响应比优先调度算法(Highest Response-ratio Next，HRN)。**最高响应比优先调度算法是对短作业优先调度算法和先来先服务调度算法的一种综合**。在每次调度作业时，先计算后备作业队列中每个作业的**响应比**，然后挑选响应比最高者投入运行。

   响应比的定义如下：
   $$
   响应比 = \frac{等待时间+要求服务时间}{要求服务时间}
   $$

2. 算法特点：

   - 有利于短作业---如果等待时间相同，短作业优先；
   - 考虑等待时间---如果作业长度相同，等待时间长的作业优先运行；
   - 不会饥饿---对于长作业，等待的时间足够长时，响应比升高，从而可以获得处理机。

3. 实际测试

   测试用例如下：

   设有A、B、C、D、E五个进程，和要求服务时间如下，采用最高响应比优先调度算法，试计算其平均周转时间和平均带权周转时间。

   ![](../assets/%E6%9C%80%E9%AB%98%E5%93%8D%E5%BA%94%E6%AF%94%E4%BC%98%E5%85%88%E7%AE%97%E6%B3%95%E6%B5%8B%E8%AF%95%E5%AE%9E%E4%BE%8B.png)

   进程调度顺序如下：

   ![](../assets/%E6%9C%80%E9%AB%98%E5%93%8D%E5%BA%94%E6%AF%94%E4%BC%98%E5%85%88%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95.png)

##### 时间片轮转调度算法

1. 简介

   时间片轮转调度算法(Round Robin，RR)。系统将所有就绪进程按到达时间的先后次序排成一个队列（FIFO队列），每次调度时把CPU分配给队首进程，并令其执行一个时间片。当时间片用完时，停止该进程的执行，将它送至就绪队列末尾等待下一次执行，然后再把处理机分配给就绪队列中的新队首进程。如此不断循环，直至完成为止。

2. 测试实例

   略

##### 多级反馈队列调度算法

1. 简介

   多级反馈队列调度算法(Multi-level Feedback Queues，MFQ)。设置多个就绪队列，并为每个队列赋予不同的优先级。不同队列的时间片长度不一样。

   - 第1个队列的优先级最高，第2队列次之，其余队列的优先级逐次降低。
   - 同一队列中进程执行的时间片大小相同，不同队列时间片大小不同，队列的优先级越高，其相应的时间片就越短。
   - 当一个新进程进入系统时，首先将它放入第1个队列的末尾，按先来先服务的原则排队等待调度。如果进程在一个时间片结束时尚未完成，调度程序便将该进程转入下一队列的末尾，再同样地按先来先服务原则等待调度执行。如此下去，最后一个队列中使用基本的时间片轮转调度算法（即时间片结束未完成的进程仍加到本队列末尾）。
   - 仅当第1个队列为空时，调度程序才调度第2队列中的进程运行；仅当第1个至第（i－1）个队列均为空时，才会调度第i个队列中的进程运行。
   - }当处理机正在为第i个队列中的某进程服务时，若又有新进程进入优先级较高的队列中，则此时新进程将**抢占**正在运行进程的处理机，即由调度程序把正在执行进程放回第i个队列末尾，重新将处理机分配给新进程。

2. 实际测试

   略

3. 性能

   多级反馈队列调度算法能较好满足各类用户的需求：

   - 终端型用户：大多能在一个时间片内完成，响应时间较短；
   - 短批处理作业用户：能在前几个队列完成，周转时间较短；
   - 长批处理作业用户：依次在1～n队列中运行，不会长时间得不到处理。

### 线程调度

​	线程的调度，取决于支持的是内核级线程还是用户级线程。

​	对于用户级线程，内核不知道线程的存在，就给了进程很大的自主权。内核只是调度进程，进程中的调度程序选择哪个线程来运行。见java线程通信部分(信号量、wait()/notify()/notifyAll()、Condition)。

​	对于内核级线程，线程的调度就交给了系统完成。





# 死锁 ✅

### 死锁概念

​	死锁是指多个进程因竞争系统资源而造成的一种僵局，若无外力作用，这些进程永远都不能向前推进。

### 产生死锁的原因

- 竞争资源：多个进程竞争资源，而资源又不能同时满足其需求
- 进程推进顺序不当：进程申请资源和释放资源的顺序不当。

### 产生自锁的四个必要条件

- 互斥条件：在一段时间内某资源仅为一个进程所占有；
- 请求和保持条件：当进程因请求资源被阻塞时，已分配的资源保持不放；
- 不可剥夺条件：进程所获得的资源在未使用完毕之前，不可以被其他线程强行夺走；
- 环路等待条件：存在一个循环等待链，其中，每一个进程分别等待它前一个进程锁持有的资源，造成永远等待。

​	只要破坏这四个必要条件之一，死锁就可以防止。

### 处理死锁的基本办法

鸵鸟政策 什么也不干 

- 预防死锁：设置某些限制条件，通过破坏死锁产生的四个必要条件之一来预防死锁；
- 避免死锁：在资源的动态分配过程中，用某种方法来防止系统进入不安全状态；
- 检测死锁及解除：系统定期检测是否出现死锁，若出现则解除死锁。

### 预防死锁

- 摒弃“互斥”条件：互斥是设备本身固有的属性，此条件不能破坏；
- 摒弃“请求和保持条件”：
  - 要求进程一次申请它所需的全部资源，若有足够的资源则分配给进程，否则不分配资源，进程等待。这种方法称为**静态资源分配法**。
  - 静态资源分配法特点：简单、易于实现，但资源利用率低，进程延迟运行。
- 摒弃“不剥夺”条件：
  - 一个已保持了某些资源的进程，若新的资源请求得不到满足，则它必须释放已获得的所有资源，待以后需要时再重新申请。
  - 特点：实现复杂，释放已获得资源可能造成前一段工作的失效，重复申请和释放会增加系统开销，降低系统吞吐量
- 摒弃“循环等待”条件
  - 将所有资源按类型排队，并赋予不同序号，要求进程均严格按照序号递增的次序请求资源，同类资源一次申请完。这种方法称为**有序资源分配法**。
  - 换句话说，当一个进程申请一个资源时，必须释放其占有的需要大于该资源的其它资源。

### 避免死锁（银行家算法）

资源动态分配过程中，通过某种方法计算来预防系统进入不安全的状态，这就叫避免死锁

### 额外补充：Java中三种典型的死锁

##### 静态的锁顺序死锁

​	a和b两个方法都需要获得A锁和B锁。一个线程执行a方法且已经获得了A锁，在等待B锁；另一个线程执行了b方法且已经获得了B锁，在等待A锁。这种状态，就是发生了静态的锁顺序死锁。

```java
//可能发生静态锁顺序死锁的代码  
class StaticLockOrderDeadLock{  
    private final Object lockA=new Object();  
    private final Object lockB=new Object();  
    public void a(){  
        synchronized (lockA) {  
            synchronized (lockB) {  
                System.out.println("function a");  
            }  
        }  
    }  
      
    public void b(){  
        synchronized (lockB) {  
            synchronized (lockA) {  
                System.out.println("function b");  
            }  
        }  
    }  
}  
```

​	解决静态的锁顺序死锁的方法就是：所有需要多个锁的线程，都要以相同的顺序来获得锁。

​	有点摒弃循环等待条件的感觉，或者说

```java
//正确的代码  
class StaticLockOrderDeadLock{  
    private final Object lockA=new Object();  
    private final Object lockB=new Object();  
    public void a(){  
        synchronized (lockA) {  
            synchronized (lockB) {  
                System.out.println("function a");  
            }  
        }  
    }  
      
    public void b(){  
        synchronized (lockA) {  
            synchronized (lockB) {  
                System.out.println("function b");  
            }  
        }  
    }  
}  
```

##### 动态的锁顺序死锁

​	动态的锁顺序死锁是指两个线程调用同一个方法时，传入的参数颠倒造成的死锁。如下代码，一个线程调用了transferMoney方法并传入参数accountA,accountB；另一个线程调用了transferMoney方法并传入参数accountB,accountA。此时就可能发生在静态的锁顺序死锁中存在的问题，即：第一个线程获得了accountA锁并等待accountB锁，第二个线程获得了accountB锁并等待accountA锁。

**对，一个对象，一个类，只有一个锁**

```java
//可能发生动态锁顺序死锁的代码  
class DynamicLockOrderDeadLock{  
    public void transefMoney(Account fromAccount,Account toAccount,Double amount){  
        synchronized (fromAccount) {  
            synchronized (toAccount) {  
                //...  
                fromAccount.minus(amount);  
                toAccount.add(amount);  
                //...  
            }  
        }  
    }  
}  
```

​	动态的锁顺序死锁解决方案如下：使用System.identifyHashCode来定义锁的顺序。确保所有的线程都以相同的顺序获得锁 。

//本来方法里写的获取锁的顺序是一致的，但是传参的时候点到了，导致动态死锁的发生

```java
//正确的代码  
class DynamicLockOrderDeadLock{  
    private final Object myLock=new Object();  
    public void transefMoney(final Account fromAccount,final Account toAccount,final Double amount){  
        class Helper{  
            public void transfer(){  
                //...  
                fromAccount.minus(amount);  
                toAccount.add(amount);  
                //...  
            }  
        }  
        int  fromHash=System.identityHashCode(fromAccount);  
        int  toHash=System.identityHashCode(toAccount);  
          
        if(fromHash<toHash){  
            synchronized (fromAccount) {  
                synchronized (toAccount) {  
                    new Helper().transfer();  
                }  
            }  
        }else if(fromHash>toHash){  
            synchronized (toAccount) {  
                synchronized (fromAccount) {  
                    new Helper().transfer();  
                }  
            }  
        }else{  
            synchronized (myLock) {  
                synchronized (fromAccount) {  
                    synchronized (toAccount) {  
                        new Helper().transfer();  
                    }  
                }  
            }  
        }  
          
    }  
}  
```

##### 协作对象之间发生的死锁

​	有时，死锁并不会那么明显，比如两个相互协作的类之间的死锁，比如下面的代码：一个线程调用了Taxi对象的setLocation方法，另一个线程调用了Dispatcher对象的getImage方法。此时可能会发生，第一个线程持有Taxi对象锁并等待Dispatcher对象锁，另一个线程持有Dispatcher对象锁并等待Taxi对象锁。

协作对象，互相需要用到相应函数，而导致的死锁。

//这个就是我们经常写的，协作对象之间发生的死锁

```java
//可能发生死锁  
class Taxi{  
    private Point location,destination;  
    private final Dispatcher dispatcher;  
    public Taxi(Dispatcher dispatcher) {  
        this.dispatcher=dispatcher;  
    }  
    public synchronized Point getLocation(){  
        return location;  
    }  
    public synchronized void setLocation(Point location){  
        this.location=location;  
        if(location.equals(destination))  
            dispatcher.notifyAvailable(this);//外部调用方法，可能等待Dispatcher对象锁  
    }  
}  
class Dispatcher{  
    private final Set<Taxi> taxis;  
    private final Set<Taxi> availableTaxis;  
    public Dispatcher(){  
        taxis=new HashSet<Taxi>();  
        availableTaxis=new HashSet<Taxi>();  
    }  
    public synchronized void notifyAvailable(Taxi taxi){  
        availableTaxis.add(taxi);  
    }  
    public synchronized Image getImage(){  
        Image image=new Image();  
        for(Taxi t:taxis)  
            image.drawMarker(t.getLocation());//外部调用方法，可能等待Taxi对象锁  
        return image;  
    }  
}  
```

​	上面的代码中，**我们在持有锁的情况下调用了外部的方法，这是非常危险的（可能发生死锁）。为了避免这种危险的情况发生，**我们使用开放调用。如果调用某个外部方法时不需要持有锁，我们称之为开放调用。

​	解决协作对象之间发生的死锁：需要使用开放调用，即避免在持有锁的情况下调用外部的方法。

```java
//正确的代码  
class Taxi{  
    private Point location,destination;  
    private final Dispatcher dispatcher;  
    public Taxi(Dispatcher dispatcher) {  
        this.dispatcher=dispatcher;  
    }  
    public synchronized Point getLocation(){  
        return location;  
    }  
    public void setLocation(Point location){  
        boolean flag=false;  
        synchronized (this) {  
            this.location=location;  
            flag=location.equals(destination);            
        }  
        if(flag)  
            dispatcher.notifyAvailable(this);//使用开放调用  
    }  
}  
class Dispatcher{  
    private final Set<Taxi> taxis;  
    private final Set<Taxi> availableTaxis;  
    public Dispatcher(){  
        taxis=new HashSet<Taxi>();  
        availableTaxis=new HashSet<Taxi>();  
    }  
    public synchronized void notifyAvailable(Taxi taxi){  
        availableTaxis.add(taxi);  
    }  
    public Image getImage(){  
        Set<Taxi> copy;  
        synchronized (this) {  
            copy=new HashSet<Taxi>(taxis);  
        }  
        Image image=new Image();  
        for(Taxi t:copy)  
            image.drawMarker(t.getLocation());//使用开放调用  
        return image;  
    }  
}  
```

# 存储器管理

### 存储器的层次结构

​	多级存储器的层次结构如下：

![](../assets/%E5%A4%9A%E7%BA%A7%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84.png)

注：

- 主存储器（主存、内存）

  保存进程运行时的程序和数据。

- 寄存器

  访问速度最快、容量小、价格昂贵，位于CPU内，暂存指令、地址、数据等。

- 高速缓存

  容量大于寄存器，速度快于主存。利用程序执行的局部性原理，经主存中经常要用到的信息存放在高速缓存中，减少访问主存的次数。

- 磁盘缓存

  将频繁使用的磁盘数据暂时存放在磁盘缓存中，可以减少访问磁盘的次数。

### 程序的装入和链接

##### 整体流程图

![](../assets/%E7%A8%8B%E5%BA%8F%E7%9A%84%E8%A3%85%E5%85%A5%E5%92%8C%E9%93%BE%E6%8E%A5%E6%B5%81%E7%A8%8B.png)

##### 程序的装入

##### 绝对装入方式(Absolute Loading Mode) 

目标模块采用绝对地址。即逻辑地址和实际内存地址完全相同，装入时不需对地址进行变换。

特点：适用于单道环境。

##### 可重定位装入方式(Relocation Loading Mode)

一次重定位，但是程序运行时不能在内存中移动，程序需要连续的空间，难以共享

多道环境下，目标模块的起始地址通常从0开始。根据内存的当前情况，将目标模块装入到内存适当位置。采用静态地址变换。

静态地址变换：又称静态地址重定位，地址变换在程序装入时一次完成，以后不再改变。

特点：不需硬件支持，但程序运行时不能在内存移动，程序需要连续存储空间，难以共享。

![](../assets/%E9%9D%99%E6%80%81%E5%9C%B0%E5%9D%80%E5%8F%98%E6%8D%A2%E7%A4%BA%E6%84%8F%E5%9B%BE.png)

##### 动态运行时装入方式(Dynamic Run-time Loading)

动态运行时的装入程序，在把装入模块装入内存后，并不立即把装入模块中的相对地址转换为绝对地址，而是把这种地址转换推迟到程序真正要执行时才进行。因此， 装入内存后的所有地址都仍是相对地址。 

重定位寄存器，逻辑地址，可以实现虚拟存储

运行时装入 需要硬件支持，就如同虚拟内存一样

特点：需要硬件支持。程序可以在内存中移动，可以实现虚拟存储。



现在计算机用的都是动态运行时装入的方式

![](../assets/%E5%8A%A8%E6%80%81%E5%9C%B0%E5%9D%80%E5%8F%98%E6%8D%A2%E7%A4%BA%E6%84%8F%E5%9B%BE.png)



### 静态链接与动态链接 ✅

1. 静态链接

   程序运行前，先将各目标模块以及它们所需的库函数，链接成一个完整的装入模块，不在拆开。

   有点静态代码块的感觉 

   JVM中的解析也是这一步，但是仅仅是获得直接引用 并不赋值

2. 装入时动态链接

   在装入时采用边装入边链接的方式装入。

   优点：便于修改和更新；便于实现目标模块共享

3. 运行时动态链接

   对模块的链接推迟到程序执行时才去进行链接。

   优点：加快装入过程；节省内存空间

### CPU通过MMU

界限地址寄存器和重定位寄存器，和数组差不多，基地址+指针）



### 内存分配管理方式

##### 分区概述

```
固定分区，将内存分为多个固定大小的分区，每个分区只能容纳一个进程，因此多道程序的，
动态分区，
再一个还有个适配的解决方案
1.首次适应
2.最佳适应
3.最差适应
无论是固定分区还是动态分区，都会存在内存碎片的问题，分区的解决方案，无论是内部碎片还是外部碎片
```

##### 连续分配方式

1. 简介

   连续分配方式，是指为一个用户程序分配一个连续的内存空间。包括单一连续分配、固定分区分配、动态分区分配、动态重定位分配

2. 单一连续分配

   把内存分为系统区和用户区两部分，系统区仅提供给OS使用，通常是放在内存的低址部分；用户区是指除系统区以外的全部内存空间，提供给用户使用。 

   特点：最简单；适用于单用户、单任务的OS

3. 固定分区分配

   - 简介

     ​	固定分区分配是多道程序系统中采用的一种最简单的存储管理方法。预先将内存空间划分为若干个固定大小的分区，每个分区中可以装入一道程序。分区的位置及大小在运行期间不能改变。各分区的大小可以相等，也可以不相等。

     ​	两个固定：

     	1、各分区的大小固定不变；

     	2、总分区的个数固定不变

     常用的空闲分区管理的数据结构有：空闲分区表和空闲分区链。

   - 分区使用表

     用一个空闲分区表来登记系统中的空闲分区，其表项类似于固定分区。空闲分区表示意图如下：

     ![](../assets/%E7%A9%BA%E9%97%B2%E5%88%86%E5%8C%BA%E8%A1%A8.png)

     

   - 空闲分区链

     将内存中的空闲分区以链表方式链接起来，构成空闲分区链。空闲分区链示意图如下：

     ![](../assets/%E7%A9%BA%E9%97%B2%E5%88%86%E5%8C%BA%E9%93%BE.png)

   - **分区分配算法**

     ​	不论是空闲分区链管理还是空闲分区表管理，链和表中的空闲区都可按一定规则排列，例如按空闲区从大到小排，以方便空闲区的查找和回收。

     **一个分区装配一个程序**

     ​	常用的动态分区管理的分配算法有：首次适应算法、循环首次适应算法、最佳适应算法、最坏适应算法。

     - 首次适应算法

       ​	首次适应算法又称最先适应算法，**该算法要求空闲分区按地址递增的次序排列**。

       ​	在进行内存分配时，从空闲分区表（或空闲分区链）首开始顺序查找，直到找到第一个能满足其大小要求的空闲分区为止。然后，再按照作业大小，从该分区中划出一块内存空间分配给请求者，余下的空闲分区仍然留在空闲分区表（或空闲分区链）中。

       ​	特点：优先利用内存低地址端，高地址端有大空闲区。但低地址端有许多小空闲分区时会增加查找开销。

     - 循环首次适应算法

       ​	循环首次适应算法又称下次适应算法，它是首次适应算法的变形。**空闲分区仍然是按地址递增的次序排列。**

       ​	该算法在为进程分配内存空间时，从上次找到的空闲分区的下一个空闲分区开始查找，直到找到第一个能满足其大小要求的空闲分区为止。然后，再按照作业大小，从该分区中划出一块内存空间分配给请求者，余下的空闲分区仍然留在空闲分区表（或空闲分区链）中。

       ​	特点：使存储空间的利用更加均衡，但会使系统缺乏大的空闲分区。

     - 最佳适应算法

       ​	**最佳适应算法要求空闲分区按容量大小递增的次序排列。**

       ​	在进行内存分配时，从空闲分区表（或空闲分区链）首开始顺序查找，直到找到第一个能满足其大小要求的空闲分区为止。如果该空闲分区大于作业的大小，则从该分区中划出一块内存空间分配给请求者，将剩余空闲区插入到空闲分区表（或空闲分区链）中的适当位置。

       ​	按最佳适应算法为作业分配内存，就能把既满足作业要求又与作业大小最接近的空闲分区分配给作业。

       ​	特点：保留了大的空闲区。但分割后的剩余空闲区很小。

     - 最坏适应算法

       ​	**最坏适应算法要求空闲分区按容量大小递减的次序排列。**

       ​	在进行内存分配时，先检查空闲分区表（或空闲分区链）中的第一个空闲分区，若第一个空闲分区小于作业要求的大小，则分配失败；否则从该空闲分区中划出与作业大小相等的一块内存空间分配给请求者，余下的空闲分区仍插入到空闲分区表（或空闲分区链）中的适当位置。

       ​	特点：分区分配之后剩下的空闲区域（新空闲区）比较大，但当大作业到来时，其存储空间的申请往往得不到满足。

   - 分区回收

     回收分区时，应将空闲区插入适当位置，此时待回收的分区可能会出现如下四种情况：

     - 回收分区r上面邻接一个空闲分区

       此时应将回收区r与上邻接分区F1合并成一个连续的空闲区。合并分区的首地址为空闲区F1的首地址，其大小为二者之和。总的空闲分区数不变。

     - 回收分区r下面邻接一个空闲分区

       此时应将回收区r与下邻接分区F2合并成一个连续的空闲区。合并分区的首地址为回收分区r的首地址，其大小为二者之和。总的空闲分区数不变。

     - 回收分区r上面、下面各邻接一个空闲分区

       此时应将回收区r与上、下邻接分区合并成一个连续的空闲区。合并分区的首地址为与r上邻接空闲区F1的首地址，其大小为三者之和，且应将与r下邻接的空闲区F2从空闲分区表(或空闲分区链)中删去。总的空闲分区数减少一个。

     - 回收分区r不与任何空闲分区相邻

       这时应为回收区单独建立一个新表项，填写分区大小及起始地址等信息，并将其加入到空闲分区表(或空闲分区链)中的适当位置。总的空闲分区数增加一个。

4. 动态分区分配

   优点：相对灵活，没有固定分区中程序数目的限制和程序大小的限制。

   缺点：每道程序总是要求占用主存的连续存储区域，主存中会产生许多碎片（外碎片）。

5. 伙伴系统

   ​	固定分区存储管理限制了内存中的进程数，动态分区的拼接需要大量时间，而伙伴系统是一种较为实用的动态存储管理办法。伙伴系统**采用伙伴算法对空闲内存进行管理**。该方法**通过不断对分大的空闲存储块来获得小的空闲存储块。当内存块释放时，应尽可能合并空闲块**。

   ​	设系统初始时可供分配的空间为2m个单元（作为一个空闲块）。当进程申请大小为n的空间时，设2^i-1<n≤2^i，则为进程分配大小为2^i的空间。如系统不存在大小为2^i 的空闲块，则查找系统中是否存在大于2^i

   的空闲块，若找到则对其进行对半划分，直到产生大小为2^i的空闲块为止。

   ​	当一块被分成两个大小相等的块时，这两块称为伙伴。当进程释放存储空间时，应检查释放块的伙伴是否空闲，若空闲则合并。合并后得到的较大的空闲块也可能存在空闲伙伴，此时也应合并。重复上述过程，直至没有可以合并的伙伴为止。

   ​	伙伴系统的缺点：分配和回收时需要对伙伴进行分拆及合并，增加了系统开销（但好于拼接）；存储空间有浪费。

6. 动态重定位分配

   ​	连续分配方式中，必须把作业装入到一片连续的内存空间中。这种分配方法能满足多道程序设计的需要，但存在碎片问题。碎片也可称为零头，是指内存中无法被利用的存储空间。

   - **内部碎片是指分配给作业的存储空间中未被利用的部分。**
   - **外部碎片是指系统中无法利用的小存储块。**

   ​	**拼接**：解决碎片问题的办法之一，即通过移动内存中的进程，把多个分散的小分区拼接成一个大分区，也可称为紧缩或紧凑。拼接的缺点是要耗费大量处理机时间。

   **紧缩 或者拼凑的方式，这个其实如同标记整理法，将存活的对象向一侧移动** 

   ​	拼接示意图如下：

   ![](../assets/%E6%8B%BC%E6%8E%A5%E7%A4%BA%E6%84%8F%E5%9B%BE.png)

   ​	拼接要解决的技术问题：空闲区放在何处：拼接后的空闲区放在何处不能一概而论，应根据移动信息量的多少来决定。

   ​	拼接的时机：
   
- 每次回收分区时拼接。只有一个空闲区，但拼接频率过高增加系统开销。
   - 找不到足够大的空闲区且系统空闲空间总量能满足要求时拼接。拼接频率小于前者，空闲区管理稍复杂。也可以只拼接部分空闲区。

   

   
   
   ​	**动态重定位**：拼接后程序在内存的位置发生变化，因此需要动态重定位技术支持。其示意图如下：
   
   动态运行时装入的实现？
   
   ​	![](../assets/%E5%8A%A8%E6%80%81%E9%87%8D%E5%AE%9A%E4%BD%8D%E7%A4%BA%E6%84%8F%E5%9B%BE.png)
   
   

##### 基本分页存储管理方式 

内存管理单元（MMU）管理着地址空间和物理内存的转换，其中的页表（Page table）存储着页（程序地址空间）和页框（物理内存空间）的映射表。

##### 虚拟内存

一个虚拟地址分成两个部分，一部分存储页面号，一部分存储偏移量。

下图的页表存放着 16 个页，这 16 个页需要用 4 个比特位来进行索引定位。例如对于虚拟地址（0010 000000000100），前 4 位是存储页面号 2，读取表项内容为（110 1），页表项最后一位表示是否存在于内存中，1 表示存在。后 12 位存储偏移量。这个页对应的页框的地址为 （110 000000000100）。

​	



​	分页式存储管理允许把一个作业存放到若干不相邻接的分区中：

- 免去移动信息
- 充分利用主存空间

无论哪种分区方式 或者分区分配算法 都会出现碎片问题

​	连续分配方式存在碎片，而紧凑技术开销太大，若能取消作业对存储区的连续性要求，则能较好地解决碎片问题。分页存储管理就是基于这一思想提出的。

​	在分页存储管理中，**将进程的逻辑地址空间划分成若干大小相等的页（或称页面），相应地将主存空间也划分成与页大小相等的块（或称物理块、页框）**。在为进程分配存储空间时，总是以块为单位来分配，即将进程中的某一页存放到主存的某一空闲块中。

​	在页面大小的选择上：页面的大小应适中。若页面太大，以至和一般进程大小相差无几，则页面分配退化为：分区分配，同时页内碎片也较大。若页面太小，虽然可减少页内碎片，但会导致页表增长。因此，页面大小应适中，通常为2的幂，一般在512B到8KB之间。

**页面太小，太大则会产生页内碎片，也表增长也会频繁的IO取表**

​	**为了在内存中找到进程的每个页面所对应的物理块，系统为每个进程建立一张页面映象表，简称页表。**

​	页表：记录页面在内存中对应物理块的数据结构。页表一般存放在内存中。页表的结构如下：

![](../assets/%E9%A1%B5%E8%A1%A8%E7%9A%84%E4%BD%9C%E7%94%A8.png)

​	此外，基于分页式存储管理方式还需要借助地址变换机构。地址变换机构的任务是实现逻辑地址到物理地址的变换，即将逻辑地址中的页号转换为内存中的物理块号。

​	现代计算机系统都支持非常大的逻辑地址空间，致使页表很大，用连续空间存放页表不现实。将页表再分页，使每页与内存物理块大小相同，并为它们进行编号0、1、…，同时还为离散存放的页表建立一张页表，称为外层页表。即两级页表、多级页表。

多级页面，其实就是个二层索引，逻辑地址的前几位代表也表号，拿页表号 去映射表取物理地址，逻辑地址的后几位为偏移量，物理地址+偏移量即可在物理内存中索引到

##### 基本分段存储管理方式 

​	引入分段存储管理，主要是满足用户需求：

- 方便编程，模块化程序设计中，程序或数据被划分成若干个大小不等，具有独立逻辑意义的分段。
- 以分段为单位进行管理，便于共享和保护，可以实现动态链接及段的动态增长。

**动态连接 就是为了模块可以共享，在运行期间才链接到具体地址**

​	在分段存储管理系统中，作业的地址空间由若干个逻辑分段组成，每个分段是一组逻辑意义相对完整的信息集合，每个分段都有自己的名字，每个分段都从0开始编址并采用一段连续的地址空间。

​	在进行存储分配时，以段为单位分配内存，每段分配一个连续的内存区，但各段之间不要求连续。

**但各段之间不连续，连续了不就是分区内存管理了，又会产生碎片问题**

​	为了实现从逻辑地址到物理地址的变换，必须为每个进程建立一个段表，用来记录每段在内存的起始地址及相关信息。其中每个表项描述一个分段的信息，至少包含：段号、段长、段在内存的起始地址、其他信息，段表一般存放在内存。段表结构如下：



用来记录每段在内存中的起始地址以及相关信息



![](../assets/%E6%AE%B5%E8%A1%A8%E7%BB%93%E6%9E%84.png)

​	为实现从逻辑地址到物理地址的转换，在系统中设置了段表寄存器，用于存放段表始址和段表长度。

段号，段长，段的起始物理地址

​	**分段与分页的区别：**

- 页是信息的物理单位，是为了减少内存碎片及提高内存利用率，是系统管理的需要。段是信息的逻辑单位，它含有一组意义相对完整的信息，分段的目的是为了更好地满足用户的需要。

- 页的大小固定且由系统决定，由硬件把逻辑地址划分为页号和页内地址两部分。段的长度不固定且由用户所编写的程序决定，通常由编译系统在对源程序进行编译时根据信息的性质来划分。

- 分页系统中作业的地址空间是一维的，分段系统中作业的地址空间是二维的（因为有长度）

  分段系统中作业的地址空间是二维的（因为有长度）

# 页调度算法

### FIFO 先进先出调度算法

没什么好说的 

### LRU 最近最少使用调度算法

- 调入也算调用一次
- 相同使用次数，替换掉最近的
- 没有其实不统计历史使用次数，就替换掉存在在cache空间里的最少使用的页



